{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from skimage.color import rgb2gray\n",
    "from PIL import Image, ImageOps\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normal dan glaukoma\n",
    "image_folder_path ={\n",
    "    'rgb':\n",
    "    {\n",
    "        'training':\n",
    "        {\n",
    "            'r2':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r2\\RGB\\datatraining\\normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r2\\RGB\\datatraining\\glaukoma\"\n",
    "            },\n",
    "            'r3':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r3\\Normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r3\\Glaucoma\"\n",
    "            }\n",
    "        },\n",
    "        'testing':\n",
    "        {\n",
    "            'r2':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r2\\RGB\\datatesting\\normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r2\\RGB\\datatesting\\glaukoma\"\n",
    "            },\n",
    "            'r3':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r3\\Normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r3\\Glaucoma\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'grayscale':\n",
    "    {\n",
    "        'training':\n",
    "        {\n",
    "            'r2':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r2\\Grayscale\\datatraining\\normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r2\\Grayscale\\datatraining\\glaukoma\"\n",
    "            },\n",
    "            'r3':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r3\\gray\\Normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r3\\gray\\Glaucoma\"\n",
    "            }\n",
    "        },\n",
    "        'testing':\n",
    "        {\n",
    "            'r2':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r2\\Grayscale\\datatesting\\normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r2\\Grayscale\\datatesting\\glaukoma\"\n",
    "            },\n",
    "            'r3':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r3\\gray\\Normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r3\\gray\\Glaucoma\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'otsu':\n",
    "    {\n",
    "        'training':\n",
    "        {\n",
    "            'r2':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r2\\Otsu\\datatraining\\normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r2\\Otsu\\datatraining\\glaukoma\"\n",
    "            },\n",
    "            'r3':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r3\\Normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r3\\Glaucoma\"\n",
    "            }\n",
    "        },\n",
    "        'testing':\n",
    "        {\n",
    "            'r2':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r2\\Otsu\\datatesting\\normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r2\\Otsu\\datatesting\\glaukoma\"\n",
    "            },\n",
    "            'r3':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r3\\Normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r3\\Glaucoma\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'otsutogray':\n",
    "    {\n",
    "        'training':\n",
    "        {\n",
    "            'r2':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r2\\OtsutoGray\\datatraining\\normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r2\\OtsutoGray\\datatraining\\glaukoma\"\n",
    "            },\n",
    "            'r3':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r3\\gray\\Normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r3\\gray\\Glaucoma\"\n",
    "            }\n",
    "        },\n",
    "        'testing':\n",
    "        {\n",
    "            'r2':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r2\\OtsutoGray\\datatesting\\normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r2\\OtsutoGray\\datatesting\\glaukoma\"\n",
    "            },\n",
    "            'r3':\n",
    "            {\n",
    "                'normal': r\"Z:\\dataset\\r3\\gray\\Normal\",\n",
    "                'glaukoma': r\"Z:\\dataset\\r3\\gray\\Glaucoma\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertImageRGBtoGrayscale(original_images_folder_path, grayscale_images_folder_path):\n",
    "    for filename in os.listdir(original_images_folder_path):\n",
    "        rgb_images_path = os.path.join(original_images_folder_path, filename)\n",
    "        new_image_save_path = os.path.join(grayscale_images_folder_path, filename)\n",
    "        \n",
    "        img = Image.open(rgb_images_path)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img.save(new_image_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvertImageRGBtoGrayscale(image_folder_path['rgb']['training']['r2']['normal'],\n",
    "                           image_folder_path['grayscale']['training']['r2']['normal'])\n",
    "ConvertImageRGBtoGrayscale(image_folder_path['rgb']['testing']['r2']['normal'],\n",
    "                           image_folder_path['grayscale']['testing']['r2']['normal'])\n",
    "ConvertImageRGBtoGrayscale(image_folder_path['rgb']['training']['r2']['glaukoma'], \n",
    "                           image_folder_path['grayscale']['training']['r2']['glaukoma'])\n",
    "ConvertImageRGBtoGrayscale(image_folder_path['rgb']['testing']['r2']['glaukoma'],\n",
    "                           image_folder_path['grayscale']['testing']['r2']['glaukoma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otsu-thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OtsuThreshold(original_images_folder_path, otsu_images_folder_path):\n",
    "    for filename in os.listdir(original_images_folder_path):\n",
    "        gray_image_path = os.path.join(original_images_folder_path, filename)\n",
    "        new_image_save_path = os.path.join(otsu_images_folder_path, filename)\n",
    "        \n",
    "        img = cv2.imread(gray_image_path)\n",
    "        grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh1 = cv2.threshold(grayimg,110,255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        Image.fromarray(thresh1).save(new_image_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OtsuThreshold(image_folder_path['grayscale']['training']['r2']['normal'],\n",
    "              image_folder_path['otsu']['training']['r2']['normal'])\n",
    "OtsuThreshold(image_folder_path['grayscale']['testing']['r2']['normal'],\n",
    "              image_folder_path['otsu']['testing']['r2']['normal'])\n",
    "OtsuThreshold(image_folder_path['grayscale']['training']['r2']['glaukoma'], \n",
    "              image_folder_path['otsu']['training']['r2']['glaukoma'])\n",
    "OtsuThreshold(image_folder_path['grayscale']['testing']['r2']['glaukoma'],\n",
    "              image_folder_path['otsu']['testing']['r2']['glaukoma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kembalikan ke grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OtsutoGray(hasil_segmentasi_otsu, image_grayscale, hasil)\n",
    "def OtsutoGray(original_images_folder_path, grayscale_images_folder_path, gray_images_folder_path):\n",
    "    for filename in os.listdir(original_images_folder_path):\n",
    "        otsu_image_path = os.path.join(original_images_folder_path, filename)\n",
    "        grayscales_image_path = os.path.join(grayscale_images_folder_path, filename)\n",
    "        new_image_save_path = os.path.join(gray_images_folder_path, filename)\n",
    "        \n",
    "        img = cv2.imread(otsu_image_path)\n",
    "        img2 = cv2.imread(grayscales_image_path)\n",
    "        toGray = img * img2\n",
    "        Image.fromarray(toGray).save(new_image_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OtsutoGray(image_folder_path['otsu']['training']['r2']['normal'],\n",
    "           image_folder_path['grayscale']['training']['r2']['normal'],\n",
    "           image_folder_path['otsutogray']['training']['r2']['normal'])\n",
    "OtsutoGray(image_folder_path['otsu']['testing']['r2']['normal'],\n",
    "           image_folder_path['grayscale']['testing']['r2']['normal'],\n",
    "           image_folder_path['otsutogray']['testing']['r2']['normal'])\n",
    "OtsutoGray(image_folder_path['otsu']['training']['r2']['glaukoma'],\n",
    "           image_folder_path['grayscale']['training']['r2']['glaukoma'],\n",
    "           image_folder_path['otsutogray']['training']['r2']['glaukoma'])\n",
    "OtsutoGray(image_folder_path['otsu']['testing']['r2']['glaukoma'],\n",
    "           image_folder_path['grayscale']['testing']['r2']['glaukoma'],\n",
    "           image_folder_path['otsutogray']['testing']['r2']['glaukoma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLCM00(dataset):\n",
    "    #membentuk matriks dengan ordo nxn dengan n adalah nilai elemen terbesar dari matriks\n",
    "    a,b = np.shape(dataset)\n",
    "    matriks = np.zeros((np.max(dataset)+1,np.max(dataset)+1))  \n",
    "    maxnilai = np.max(dataset)+1 #nilai elemen terbesar dari matriks\n",
    "    for i in range(a):\n",
    "        for j in range(b-1):\n",
    "            matriks[dataset[i][j],dataset[i][j+1]] = matriks[dataset[i][j],dataset[i][j+1]]+1\n",
    "            matriks[dataset[i][j+1],dataset[i][j]] = matriks[dataset[i][j+1],dataset[i][j]]+1\n",
    "    return matriks\n",
    "\n",
    "def GLCM45(dataset):\n",
    "    a,b = np.shape(dataset)\n",
    "    matriks = np.zeros((np.max(dataset)+1,np.max(dataset)+1))\n",
    "    maxnilai = np.max(dataset)+1\n",
    "    for i in range(a-1):\n",
    "        for j in range(b-1):\n",
    "            matriks[dataset[i+1][j],dataset[i][j+1]] = matriks[dataset[i+1][j],dataset[i][j+1]]+1\n",
    "            matriks[dataset[i][j+1],dataset[i+1][j]] = matriks[dataset[i][j+1],dataset[i+1][j]]+1\n",
    "    return matriks\n",
    "\n",
    "def GLCM90(dataset):\n",
    "    a,b = np.shape(dataset)\n",
    "    matriks = np.zeros((np.max(dataset)+1,np.max(dataset)+1))\n",
    "    maxnilai = np.max(dataset)+1\n",
    "    for i in range(a-1):\n",
    "        for j in range(b):\n",
    "            matriks[dataset[i+1][j],dataset[i][j]] = matriks[dataset[i+1][j],dataset[i][j]]+1\n",
    "            matriks[dataset[i][j],dataset[i+1][j]] = matriks[dataset[i][j],dataset[i+1][j]]+1\n",
    "    return matriks\n",
    "\n",
    "def GLCM135(dataset):\n",
    "    a,b = np.shape(dataset)\n",
    "    matriks = np.zeros((np.max(dataset)+1,np.max(dataset)+1))\n",
    "    maxnilai = np.max(dataset)+1\n",
    "    for i in range(a-1):\n",
    "        for j in range(b-1):\n",
    "            matriks[dataset[i+1][j+1],dataset[i][j]] = matriks[dataset[i+1][j+1],dataset[i][j]]+1\n",
    "            matriks[dataset[i][j],dataset[i+1][j+1]] = matriks[dataset[i][j],dataset[i+1][j+1]]+1\n",
    "    return matriks\n",
    "\n",
    "def contrast(dataset):\n",
    "    kontras=0\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset)):\n",
    "            kontras+=(i-j)**2*dataset[i][j]\n",
    "    return kontras\n",
    "\n",
    "def IDM(dataset):\n",
    "    idm=0\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset)):\n",
    "            idm+=1/(1+(i-j)**2)*dataset[i][j]\n",
    "    return idm\n",
    "\n",
    "def entropy(dataset):\n",
    "    entropi=0\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset)):\n",
    "            if dataset[i,j] != 0.0:\n",
    "                entropi+=-dataset[i][j]*math.log(dataset[i][j],10)\n",
    "    return entropi\n",
    "\n",
    "def correlation(dataset):\n",
    "    korelasi=0\n",
    "    M=0\n",
    "    T=0\n",
    "    for i in range(len(dataset)):\n",
    "        M+=i*dataset[i]\n",
    "    M2 = sum(M)\n",
    "    for i in range(len(dataset)):\n",
    "        T+=dataset[i]*(i-M2)**2\n",
    "    T2=sum(T)\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset)):\n",
    "            korelasi+=dataset[i][j]*(i-M2)*(j-M2)/T2**2\n",
    "    return korelasi\n",
    "\n",
    "def energy(dataset):\n",
    "    energi=0\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset)):\n",
    "            energi+=dataset[i][j]**2\n",
    "    return energi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisasi Matriks GLCM\n",
    "def NormalizeGLCM(dataset):\n",
    "    return dataset/sum(sum(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistik berbasis histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rerata intensitas\n",
    "def intensitas_histogram(dataset):\n",
    "    #hitung frekuensi aras keabuan\n",
    "    L = np.max(dataset)+2\n",
    "    m,n = np.shape(dataset)\n",
    "    Frek = np.zeros((L,1))\n",
    "    grayimg = dataset.astype(float)\n",
    "    for i in range(1,m) :\n",
    "        for j in range(1,n) :\n",
    "            intensitas = grayimg[i,j]\n",
    "            Frek[int(intensitas+1)] = Frek[int(intensitas+1)]+1\n",
    "\n",
    "    #hitung probabilitas\n",
    "    jum_piksel = m * n\n",
    "    Prob = np.zeros((L,1))\n",
    "    for i in range(0,(L-1)):\n",
    "        Prob[i+1]= Frek[i+1]/jum_piksel\n",
    "    \n",
    "    #hitung rerata intensitas\n",
    "    mu = 0\n",
    "    for i in range(0,(L-1)):\n",
    "        #print(Prob)\n",
    "        mu = mu + i * Prob[i+1]\n",
    "    mu = mu[0]\n",
    "    return mu\n",
    "        \n",
    "#deviasi standar\n",
    "def standar_dev_histogram(dataset):\n",
    "    #hitung frekuensi aras keabuan\n",
    "    L = np.max(dataset)+2\n",
    "    m,n = np.shape(dataset)\n",
    "    Frek = np.zeros((L,1))\n",
    "    grayimg = dataset.astype(float)\n",
    "    for i in range(1,m) :\n",
    "        for j in range(1,n) :\n",
    "            intensitas = grayimg[i,j]\n",
    "            Frek[int(intensitas+1)] = Frek[int(intensitas+1)]+1\n",
    "\n",
    "    #hitung probabilitas\n",
    "    jum_piksel = m * n\n",
    "    Prob = np.zeros((L,1))\n",
    "    for i in range(0,(L-1)):\n",
    "        Prob[i+1]= Frek[i+1]/jum_piksel\n",
    "        \n",
    "    #hitung deviasi\n",
    "    varians = 0\n",
    "    mu = intensitas_histogram(dataset)\n",
    "    for i in range(0,(L-1)):\n",
    "        varians = varians + (i-mu)**2 * Prob[i+1]\n",
    "    deviasi = math.sqrt(varians)\n",
    "    varians_n = varians / (L-1)**2 #normalisasi\n",
    "    varians_n = varians_n[0]\n",
    "    return varians_n\n",
    "\n",
    "#skewness\n",
    "def skewness_histogram(dataset):\n",
    "    #hitung frekuensi aras keabuan\n",
    "    L = np.max(dataset)+2\n",
    "    m,n = np.shape(dataset)\n",
    "    Frek = np.zeros((L,1))\n",
    "    grayimg = dataset.astype(float)\n",
    "    for i in range(1,m) :\n",
    "        for j in range(1,n) :\n",
    "            intensitas = grayimg[i,j]\n",
    "            Frek[int(intensitas+1)] = Frek[int(intensitas+1)]+1\n",
    "\n",
    "    #hitung probabilitas\n",
    "    jum_piksel = m * n\n",
    "    Prob = np.zeros((L,1))\n",
    "    for i in range(0,(L-1)):\n",
    "        Prob[i+1]= Frek[i+1]/jum_piksel\n",
    "        \n",
    "    #menghitung skewness\n",
    "    skewness = 0\n",
    "    mu = intensitas_histogram(dataset)\n",
    "    for i in range(0,(L-1)):\n",
    "        skewness = skewness + (i-mu)**3 * Prob[i+1]\n",
    "    skewness = skewness / (L-1)**2\n",
    "    skewness = skewness[0]\n",
    "    return skewness\n",
    "\n",
    "#energi\n",
    "def energi_histogram(dataset):\n",
    "    #hitung frekuensi aras keabuan\n",
    "    L = np.max(dataset)+2\n",
    "    m,n = np.shape(dataset)\n",
    "    Frek = np.zeros((L,1))\n",
    "    grayimg = dataset.astype(float)\n",
    "    for i in range(1,m) :\n",
    "        for j in range(1,n) :\n",
    "            intensitas = grayimg[i,j]\n",
    "            Frek[int(intensitas+1)] = Frek[int(intensitas+1)]+1\n",
    "\n",
    "    #hitung probabilitas\n",
    "    jum_piksel = m * n\n",
    "    Prob = np.zeros((L,1))\n",
    "    for i in range(0,(L-1)):\n",
    "        Prob[i+1]= Frek[i+1]/jum_piksel\n",
    "        \n",
    "    #menghitung energi\n",
    "    energi = 0\n",
    "    for i in range(0,(L-1)):\n",
    "        energi = energi + Prob[i+1]**2\n",
    "    energi = energi[0]\n",
    "    return energi\n",
    "\n",
    "#entropi\n",
    "def entropi_histogram(dataset):\n",
    "    #hitung frekuensi aras keabuan\n",
    "    L = np.max(dataset)+2\n",
    "    m,n = np.shape(dataset)\n",
    "    Frek = np.zeros((L,1))\n",
    "    grayimg = dataset.astype(float)\n",
    "    for i in range(1,m) :\n",
    "        for j in range(1,n) :\n",
    "            intensitas = grayimg[i,j]\n",
    "            Frek[int(intensitas+1)] = Frek[int(intensitas+1)]+1\n",
    "\n",
    "    #hitung probabilitas\n",
    "    jum_piksel = m * n\n",
    "    Prob = np.zeros((L,1))\n",
    "    for i in range(0,(L-1)):\n",
    "        Prob[i+1]= Frek[i+1]/jum_piksel\n",
    "        \n",
    "    #menghitung entropi\n",
    "    entropi = 0\n",
    "    for i in range(0,(L-1)):\n",
    "        if(Prob[i+1] != 0):\n",
    "            entropi = entropi + Prob[i+1] * math.log(Prob[i+1])\n",
    "    entropi = -entropi\n",
    "    entropi = entropi[0]\n",
    "    return entropi\n",
    "    \n",
    "#kehalusan\n",
    "def kehalusan_histogram(dataset):\n",
    "    varians_n = standar_dev_histogram(dataset)\n",
    "    smoothness = 1 - (1 / (1+varians_n))\n",
    "    return smoothness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataFrame():\n",
    "    return {\n",
    "        'filename' : [],\n",
    "        'contrast_00' : [],\n",
    "        'contrast_45' : [],\n",
    "        'contrast_90' : [],\n",
    "        'contrast_135' : [],\n",
    "        'IDM_00' : [],\n",
    "        'IDM_45' : [],\n",
    "        'IDM_90' : [],\n",
    "        'IDM_135' : [],\n",
    "        'entropy_00' : [],\n",
    "        'entropy_45' : [],\n",
    "        'entropy_90' : [],\n",
    "        'entropy_135' : [],\n",
    "        'corellation_00' : [],\n",
    "        'corellation_45' : [],\n",
    "        'corellation_90' : [],\n",
    "        'corellation_135' : [],\n",
    "        'energy_00' : [],\n",
    "        'energy_45' : [],\n",
    "        'energy_90' : [],\n",
    "        'energy_135' : [],\n",
    "        'intensitas_histo' : [],\n",
    "        'standar_dev_histo' : [],\n",
    "        'skewness_histo' : [],\n",
    "        'energi_histo' : [],\n",
    "        'entropi_histo' : [],\n",
    "        'kehalusan_histo' : [],\n",
    "        \n",
    "        'class' : [],\n",
    "    }\n",
    "dataframe = CreateDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Ekstraksi\n",
    "def HitungFitur(grayscale_images_folder_path, penyakit):\n",
    "    for filename in os.listdir(grayscale_images_folder_path):\n",
    "        filename2 = filename\n",
    "        filename = os.path.join(grayscale_images_folder_path, filename)\n",
    "\n",
    "        img = cv2.imread(filename, 0)\n",
    "\n",
    "        dataframe['filename'].append(filename2)\n",
    "        dataframe['contrast_00'].append(contrast(NormalizeGLCM(GLCM00(img))))\n",
    "        dataframe['contrast_45'].append(contrast(NormalizeGLCM(GLCM45(img))))\n",
    "        dataframe['contrast_90'].append(contrast(NormalizeGLCM(GLCM90(img))))\n",
    "        dataframe['contrast_135'].append(contrast(NormalizeGLCM(GLCM135(img))))\n",
    "        dataframe['IDM_00'].append(IDM(NormalizeGLCM(GLCM00(img))))\n",
    "        dataframe['IDM_45'].append(IDM(NormalizeGLCM(GLCM45(img))))\n",
    "        dataframe['IDM_90'].append(IDM(NormalizeGLCM(GLCM90(img))))\n",
    "        dataframe['IDM_135'].append(IDM(NormalizeGLCM(GLCM135(img))))\n",
    "        dataframe['entropy_00'].append(entropy(NormalizeGLCM(GLCM00(img))))\n",
    "        dataframe['entropy_45'].append(entropy(NormalizeGLCM(GLCM45(img))))\n",
    "        dataframe['entropy_90'].append(entropy(NormalizeGLCM(GLCM90(img))))\n",
    "        dataframe['entropy_135'].append(entropy(NormalizeGLCM(GLCM135(img))))\n",
    "        dataframe['corellation_00'].append(correlation(NormalizeGLCM(GLCM00(img))))\n",
    "        dataframe['corellation_45'].append(correlation(NormalizeGLCM(GLCM45(img))))\n",
    "        dataframe['corellation_90'].append(correlation(NormalizeGLCM(GLCM90(img))))\n",
    "        dataframe['corellation_135'].append(correlation(NormalizeGLCM(GLCM135(img))))\n",
    "        dataframe['energy_00'].append(energy(NormalizeGLCM(GLCM00(img))))\n",
    "        dataframe['energy_45'].append(energy(NormalizeGLCM(GLCM45(img))))\n",
    "        dataframe['energy_90'].append(energy(NormalizeGLCM(GLCM90(img))))\n",
    "        dataframe['energy_135'].append(energy(NormalizeGLCM(GLCM135(img))))\n",
    "        dataframe['intensitas_histo'].append(intensitas_histogram(img))\n",
    "        dataframe['standar_dev_histo'].append(standar_dev_histogram(img))\n",
    "        dataframe['skewness_histo'].append(skewness_histogram(img))\n",
    "        dataframe['energi_histo'].append(energi_histogram(img))\n",
    "        dataframe['entropi_histo'].append(entropi_histogram(img))\n",
    "        dataframe['kehalusan_histo'].append(kehalusan_histogram(img))\n",
    "    \n",
    "    \n",
    "        #img = cv2.imread(filename)\n",
    "        dataframe['class'].append(penyakit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ekstraks Fitur Training (Membuat dataframe untuk dataset r2)\n",
    "dataframe = CreateDataFrame()\n",
    "\n",
    "HitungFitur(image_folder_path['otsutogray']['training']['r2']['normal'],0)\n",
    "HitungFitur(image_folder_path['otsutogray']['training']['r2']['glaukoma'],1)\n",
    "\n",
    "dataframe = pd.DataFrame(data=dataframe)\n",
    "dataframe.to_csv('Ekstraksi Fitur Glaukoma [GLCM][Histo][R2][Training].csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataFrame2():\n",
    "    return {\n",
    "        'filename' : [],\n",
    "        'intensitas_histo' : [],\n",
    "        'standar_dev_histo' : [],\n",
    "        'skewness_histo' : [],\n",
    "        'energi_histo' : [],\n",
    "        'entropi_histo' : [],\n",
    "        'kehalusan_histo' : [],\n",
    "        'class' : [],\n",
    "    }\n",
    "dataframe2 = CreateDataFrame2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HitungFitur2(grayscale_images_folder_path, penyakit2):\n",
    "    for filename in os.listdir(grayscale_images_folder_path):\n",
    "        filename2 = filename\n",
    "        filename = os.path.join(grayscale_images_folder_path, filename)\n",
    "\n",
    "        img = cv2.imread(filename, 0)\n",
    "\n",
    "        dataframe2['filename'].append(filename2)\n",
    "        dataframe2['intensitas_histo'].append(intensitas_histogram(img))\n",
    "        dataframe2['standar_dev_histo'].append(standar_dev_histogram(img))\n",
    "        dataframe2['skewness_histo'].append(skewness_histogram(img))\n",
    "        dataframe2['energi_histo'].append(energi_histogram(img))\n",
    "        dataframe2['entropi_histo'].append(entropi_histogram(img))\n",
    "        dataframe2['kehalusan_histo'].append(kehalusan_histogram(img))\n",
    "    \n",
    "    #    img = cv2.imread(filename)\n",
    "        dataframe2['class'].append(penyakit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ekstraks Fitur Training (Membuat dataframe untuk dataset r2)\n",
    "dataframe2 = CreateDataFrame2()\n",
    "\n",
    "HitungFitur2(image_folder_path['otsutogray']['training']['r2']['normal'],0)\n",
    "HitungFitur2(image_folder_path['otsutogray']['training']['r2']['glaukoma'],1)\n",
    "\n",
    "dataframe2 = pd.DataFrame(data=dataframe2)\n",
    "dataframe2.to_csv('Dataframe Glaukoma [histo][R2][Training].csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
