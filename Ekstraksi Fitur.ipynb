{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "# from skimage.color import rgb2gray\n",
    "# from PIL import Image, ImageOps\n",
    "# import skimage.io as io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normal dan glaukoma\n",
    "image_folder_path ={\n",
    "    'togray':\n",
    "    {\n",
    "        'otsu':\n",
    "        {\n",
    "            'r2':\n",
    "            {\n",
    "                'normal' : r\".\\dataset\\R2\\toGray\\otsu\\normal\",\n",
    "                'glaukoma': r\".\\dataset\\R2\\toGray\\otsu\\glaukoma\",\n",
    "            },\n",
    "            'r3':\n",
    "            {\n",
    "                'normal' : r\".\\dataset\\R3\\toGray\\otsu\\normal\",\n",
    "                'glaukoma': r\".\\dataset\\R3\\toGray\\otsu\\glaukoma\",\n",
    "            },\n",
    "            'r2r3':\n",
    "            {\n",
    "                'normal' : r\".\\dataset\\r2r3\\otsu\\normal\",\n",
    "                'glaukoma': r\".\\dataset\\r2r3\\otsu\\glaukoma\",\n",
    "            }                \n",
    "        },\n",
    "        'canny':\n",
    "        {\n",
    "            'r2':\n",
    "            {\n",
    "                'normal' : r\".\\dataset\\R2\\toGray\\canny\\normal\",\n",
    "                'glaukoma': r\".\\dataset\\R2\\toGray\\canny\\glaukoma\",\n",
    "            },\n",
    "            'r3':\n",
    "            {\n",
    "                'normal' : r\".\\dataset\\R3\\toGray\\canny\\normal\",\n",
    "                'glaukoma': r\".\\dataset\\R3\\toGray\\canny\\glaukoma\",\n",
    "            },\n",
    "            'r2r3':\n",
    "            {\n",
    "                'normal' : r\".\\dataset\\r2r3\\canny\\normal\",\n",
    "                'glaukoma': r\".\\dataset\\r2r3\\canny\\glaukoma\",\n",
    "            }                \n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLCM00(dataset):\n",
    "    #membentuk matriks dengan ordo nxn dengan n adalah nilai elemen terbesar dari matriks\n",
    "    a,b = np.shape(dataset)\n",
    "    matriks = np.zeros((np.max(dataset)+1,np.max(dataset)+1))  \n",
    "    maxnilai = np.max(dataset)+1 #nilai elemen terbesar dari matriks\n",
    "    for i in range(a):\n",
    "        for j in range(b-1):\n",
    "            matriks[dataset[i][j],dataset[i][j+1]] = matriks[dataset[i][j],dataset[i][j+1]]+1\n",
    "            matriks[dataset[i][j+1],dataset[i][j]] = matriks[dataset[i][j+1],dataset[i][j]]+1\n",
    "    return matriks\n",
    "\n",
    "def GLCM45(dataset):\n",
    "    a,b = np.shape(dataset)\n",
    "    matriks = np.zeros((np.max(dataset)+1,np.max(dataset)+1))\n",
    "    maxnilai = np.max(dataset)+1\n",
    "    for i in range(a-1):\n",
    "        for j in range(b-1):\n",
    "            matriks[dataset[i+1][j],dataset[i][j+1]] = matriks[dataset[i+1][j],dataset[i][j+1]]+1\n",
    "            matriks[dataset[i][j+1],dataset[i+1][j]] = matriks[dataset[i][j+1],dataset[i+1][j]]+1\n",
    "    return matriks\n",
    "\n",
    "def GLCM90(dataset):\n",
    "    a,b = np.shape(dataset)\n",
    "    matriks = np.zeros((np.max(dataset)+1,np.max(dataset)+1))\n",
    "    maxnilai = np.max(dataset)+1\n",
    "    for i in range(a-1):\n",
    "        for j in range(b):\n",
    "            matriks[dataset[i+1][j],dataset[i][j]] = matriks[dataset[i+1][j],dataset[i][j]]+1\n",
    "            matriks[dataset[i][j],dataset[i+1][j]] = matriks[dataset[i][j],dataset[i+1][j]]+1\n",
    "    return matriks\n",
    "\n",
    "def GLCM135(dataset):\n",
    "    a,b = np.shape(dataset)\n",
    "    matriks = np.zeros((np.max(dataset)+1,np.max(dataset)+1))\n",
    "    maxnilai = np.max(dataset)+1\n",
    "    for i in range(a-1):\n",
    "        for j in range(b-1):\n",
    "            matriks[dataset[i+1][j+1],dataset[i][j]] = matriks[dataset[i+1][j+1],dataset[i][j]]+1\n",
    "            matriks[dataset[i][j],dataset[i+1][j+1]] = matriks[dataset[i][j],dataset[i+1][j+1]]+1\n",
    "    return matriks\n",
    "\n",
    "def contrast(dataset):\n",
    "    kontras=0\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset)):\n",
    "            kontras+=(i-j)**2*dataset[i][j]\n",
    "    return kontras\n",
    "\n",
    "def IDM(dataset):\n",
    "    idm=0\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset)):\n",
    "            idm+=1/(1+(i-j)**2)*dataset[i][j]\n",
    "    return idm\n",
    "\n",
    "def entropy(dataset):\n",
    "    entropi=0\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset)):\n",
    "            if dataset[i,j] != 0.0:\n",
    "                entropi+=-dataset[i][j]*math.log(dataset[i][j],10)\n",
    "    return entropi\n",
    "\n",
    "def correlation(dataset):\n",
    "    korelasi=0\n",
    "    M=0\n",
    "    T=0\n",
    "    for i in range(len(dataset)):\n",
    "        M+=i*dataset[i]\n",
    "    M2 = sum(M)\n",
    "    for i in range(len(dataset)):\n",
    "        T+=dataset[i]*(i-M2)**2\n",
    "    T2=sum(T)\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset)):\n",
    "            korelasi+=dataset[i][j]*(i-M2)*(j-M2)/T2**2\n",
    "    return korelasi\n",
    "\n",
    "def energy(dataset):\n",
    "    energi=0\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset)):\n",
    "            energi+=dataset[i][j]**2\n",
    "    return energi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisasi Matriks GLCM\n",
    "def NormalizeGLCM(dataset):\n",
    "    return dataset/sum(sum(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistik Berbasis Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rerata intensitas\n",
    "def intensitas_histogram(dataset):\n",
    "    #hitung frekuensi aras keabuan\n",
    "    L = np.max(dataset)+2\n",
    "    m,n = np.shape(dataset)\n",
    "    Frek = np.zeros((L,1))\n",
    "    grayimg = dataset.astype(float)\n",
    "    for i in range(1,m) :\n",
    "        for j in range(1,n) :\n",
    "            intensitas = grayimg[i,j]\n",
    "            Frek[int(intensitas+1)] = Frek[int(intensitas+1)]+1\n",
    "\n",
    "    #hitung probabilitas\n",
    "    jum_piksel = m * n\n",
    "    Prob = np.zeros((L,1))\n",
    "    for i in range(0,(L-1)):\n",
    "        Prob[i+1]= Frek[i+1]/jum_piksel\n",
    "    \n",
    "    #hitung rerata intensitas\n",
    "    mu = 0\n",
    "    for i in range(0,(L-1)):\n",
    "        #print(Prob)\n",
    "        mu = mu + i * Prob[i+1]\n",
    "    mu = mu[0]\n",
    "    return mu\n",
    "        \n",
    "#deviasi standar\n",
    "def standar_dev_histogram(dataset):\n",
    "    #hitung frekuensi aras keabuan\n",
    "    L = np.max(dataset)+2\n",
    "    m,n = np.shape(dataset)\n",
    "    Frek = np.zeros((L,1))\n",
    "    grayimg = dataset.astype(float)\n",
    "    for i in range(1,m) :\n",
    "        for j in range(1,n) :\n",
    "            intensitas = grayimg[i,j]\n",
    "            Frek[int(intensitas+1)] = Frek[int(intensitas+1)]+1\n",
    "\n",
    "    #hitung probabilitas\n",
    "    jum_piksel = m * n\n",
    "    Prob = np.zeros((L,1))\n",
    "    for i in range(0,(L-1)):\n",
    "        Prob[i+1]= Frek[i+1]/jum_piksel\n",
    "        \n",
    "    #hitung deviasi\n",
    "    varians = 0\n",
    "    mu = intensitas_histogram(dataset)\n",
    "    for i in range(0,(L-1)):\n",
    "        varians = varians + (i-mu)**2 * Prob[i+1]\n",
    "    deviasi = math.sqrt(varians)\n",
    "    varians_n = varians / (L-1)**2 #normalisasi\n",
    "    varians_n = varians_n[0]\n",
    "    return varians_n\n",
    "\n",
    "#skewness\n",
    "def skewness_histogram(dataset):\n",
    "    #hitung frekuensi aras keabuan\n",
    "    L = np.max(dataset)+2\n",
    "    m,n = np.shape(dataset)\n",
    "    Frek = np.zeros((L,1))\n",
    "    grayimg = dataset.astype(float)\n",
    "    for i in range(1,m) :\n",
    "        for j in range(1,n) :\n",
    "            intensitas = grayimg[i,j]\n",
    "            Frek[int(intensitas+1)] = Frek[int(intensitas+1)]+1\n",
    "\n",
    "    #hitung probabilitas\n",
    "    jum_piksel = m * n\n",
    "    Prob = np.zeros((L,1))\n",
    "    for i in range(0,(L-1)):\n",
    "        Prob[i+1]= Frek[i+1]/jum_piksel\n",
    "        \n",
    "    #menghitung skewness\n",
    "    skewness = 0\n",
    "    mu = intensitas_histogram(dataset)\n",
    "    for i in range(0,(L-1)):\n",
    "        skewness = skewness + (i-mu)**3 * Prob[i+1]\n",
    "    skewness = skewness / (L-1)**2\n",
    "    skewness = skewness[0]\n",
    "    return skewness\n",
    "\n",
    "#energi\n",
    "def energi_histogram(dataset):\n",
    "    #hitung frekuensi aras keabuan\n",
    "    L = np.max(dataset)+2\n",
    "    m,n = np.shape(dataset)\n",
    "    Frek = np.zeros((L,1))\n",
    "    grayimg = dataset.astype(float)\n",
    "    for i in range(1,m) :\n",
    "        for j in range(1,n) :\n",
    "            intensitas = grayimg[i,j]\n",
    "            Frek[int(intensitas+1)] = Frek[int(intensitas+1)]+1\n",
    "\n",
    "    #hitung probabilitas\n",
    "    jum_piksel = m * n\n",
    "    Prob = np.zeros((L,1))\n",
    "    for i in range(0,(L-1)):\n",
    "        Prob[i+1]= Frek[i+1]/jum_piksel\n",
    "        \n",
    "    #menghitung energi\n",
    "    energi = 0\n",
    "    for i in range(0,(L-1)):\n",
    "        energi = energi + Prob[i+1]**2\n",
    "    energi = energi[0]\n",
    "    return energi\n",
    "\n",
    "#entropi\n",
    "def entropi_histogram(dataset):\n",
    "    #hitung frekuensi aras keabuan\n",
    "    L = np.max(dataset)+2\n",
    "    m,n = np.shape(dataset)\n",
    "    Frek = np.zeros((L,1))\n",
    "    grayimg = dataset.astype(float)\n",
    "    for i in range(1,m) :\n",
    "        for j in range(1,n) :\n",
    "            intensitas = grayimg[i,j]\n",
    "            Frek[int(intensitas+1)] = Frek[int(intensitas+1)]+1\n",
    "\n",
    "    #hitung probabilitas\n",
    "    jum_piksel = m * n\n",
    "    Prob = np.zeros((L,1))\n",
    "    for i in range(0,(L-1)):\n",
    "        Prob[i+1]= Frek[i+1]/jum_piksel\n",
    "        \n",
    "    #menghitung entropi\n",
    "    entropi = 0\n",
    "    for i in range(0,(L-1)):\n",
    "        if(Prob[i+1] != 0):\n",
    "            entropi = entropi + Prob[i+1] * math.log(Prob[i+1])\n",
    "    entropi = -entropi\n",
    "    entropi = entropi[0]\n",
    "    return entropi\n",
    "    \n",
    "#kehalusan\n",
    "def kehalusan_histogram(dataset):\n",
    "    varians_n = standar_dev_histogram(dataset)\n",
    "    smoothness = 1 - (1 / (1+varians_n))\n",
    "    return smoothness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat rangka data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataFrame():\n",
    "    return {\n",
    "        'filename' : [],\n",
    "        'contrast_00' : [],\n",
    "        'contrast_45' : [],\n",
    "        'contrast_90' : [],\n",
    "        'contrast_135' : [],\n",
    "        'IDM_00' : [],\n",
    "        'IDM_45' : [],\n",
    "        'IDM_90' : [],\n",
    "        'IDM_135' : [],\n",
    "        'entropy_00' : [],\n",
    "        'entropy_45' : [],\n",
    "        'entropy_90' : [],\n",
    "        'entropy_135' : [],\n",
    "        'corellation_00' : [],\n",
    "        'corellation_45' : [],\n",
    "        'corellation_90' : [],\n",
    "        'corellation_135' : [],\n",
    "        'energy_00' : [],\n",
    "        'energy_45' : [],\n",
    "        'energy_90' : [],\n",
    "        'energy_135' : [],\n",
    "        'intensitas_histo' : [],\n",
    "        'standar_dev_histo' : [],\n",
    "        'skewness_histo' : [],\n",
    "        'energi_histo' : [],\n",
    "        'entropi_histo' : [],\n",
    "        'kehalusan_histo' : [],\n",
    "        \n",
    "        'class' : [],\n",
    "    }\n",
    "dataframe = CreateDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Ekstraksi\n",
    "def HitungFitur(grayscale_images_folder_path, penyakit):\n",
    "    for filename in os.listdir(grayscale_images_folder_path):\n",
    "        filename2 = filename\n",
    "        filename = os.path.join(grayscale_images_folder_path, filename)\n",
    "\n",
    "        img = cv2.imread(filename, 0)\n",
    "\n",
    "        dataframe['filename'].append(filename2)\n",
    "        dataframe['contrast_00'].append(contrast(NormalizeGLCM(GLCM00(img))))\n",
    "        dataframe['contrast_45'].append(contrast(NormalizeGLCM(GLCM45(img))))\n",
    "        dataframe['contrast_90'].append(contrast(NormalizeGLCM(GLCM90(img))))\n",
    "        dataframe['contrast_135'].append(contrast(NormalizeGLCM(GLCM135(img))))\n",
    "        dataframe['IDM_00'].append(IDM(NormalizeGLCM(GLCM00(img))))\n",
    "        dataframe['IDM_45'].append(IDM(NormalizeGLCM(GLCM45(img))))\n",
    "        dataframe['IDM_90'].append(IDM(NormalizeGLCM(GLCM90(img))))\n",
    "        dataframe['IDM_135'].append(IDM(NormalizeGLCM(GLCM135(img))))\n",
    "        dataframe['entropy_00'].append(entropy(NormalizeGLCM(GLCM00(img))))\n",
    "        dataframe['entropy_45'].append(entropy(NormalizeGLCM(GLCM45(img))))\n",
    "        dataframe['entropy_90'].append(entropy(NormalizeGLCM(GLCM90(img))))\n",
    "        dataframe['entropy_135'].append(entropy(NormalizeGLCM(GLCM135(img))))\n",
    "        dataframe['corellation_00'].append(correlation(NormalizeGLCM(GLCM00(img))))\n",
    "        dataframe['corellation_45'].append(correlation(NormalizeGLCM(GLCM45(img))))\n",
    "        dataframe['corellation_90'].append(correlation(NormalizeGLCM(GLCM90(img))))\n",
    "        dataframe['corellation_135'].append(correlation(NormalizeGLCM(GLCM135(img))))\n",
    "        dataframe['energy_00'].append(energy(NormalizeGLCM(GLCM00(img))))\n",
    "        dataframe['energy_45'].append(energy(NormalizeGLCM(GLCM45(img))))\n",
    "        dataframe['energy_90'].append(energy(NormalizeGLCM(GLCM90(img))))\n",
    "        dataframe['energy_135'].append(energy(NormalizeGLCM(GLCM135(img))))\n",
    "        dataframe['intensitas_histo'].append(intensitas_histogram(img))\n",
    "        dataframe['standar_dev_histo'].append(standar_dev_histogram(img))\n",
    "        dataframe['skewness_histo'].append(skewness_histogram(img))\n",
    "        dataframe['energi_histo'].append(energi_histogram(img))\n",
    "        dataframe['entropi_histo'].append(entropi_histogram(img))\n",
    "        dataframe['kehalusan_histo'].append(kehalusan_histogram(img))\n",
    "    \n",
    "    \n",
    "        #img = cv2.imread(filename)\n",
    "        dataframe['class'].append(penyakit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "#Ekstraks Fitur Training (Membuat dataframe untuk dataset r2)\n",
    "dataframe = CreateDataFrame()\n",
    "\n",
    "HitungFitur(image_folder_path['togray']['otsu']['r2r3']['normal'],0)\n",
    "HitungFitur(image_folder_path['togray']['otsu']['r2r3']['glaukoma'],1)\n",
    "\n",
    "dataframe = pd.DataFrame(data=dataframe)\n",
    "dataframe.to_csv('Otsu r2r3 dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
